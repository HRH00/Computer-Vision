{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Images added for Harry\n",
      "20 Images added for Phil\n",
      "40 Images added in total \n",
      "DONE\n",
      "\n",
      "Extracting LBM features\n",
      "DONE\n",
      "\n",
      "Training SVM classifier\n",
      "DONE\n",
      "\n",
      "Testing SVM Classifier\n",
      "[1, 1, 1, 0, 0, 0, 1, 0]\n",
      "Accuracy: 0.625\n",
      "DONE\n",
      "\n",
      "Saving Classifier\n",
      "Saved\n",
      "\n",
      "COMPLETED\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score    \n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "#global constants\n",
    "ROI_SIZE_XY=200\n",
    "MAX_IMAGES = 20\n",
    "NAMES = [\"Harry\",\"Phil\"]#,\"Maureen\"]\n",
    "\n",
    "def getFiles(NAME):\n",
    "    cascade_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    DATABASE_PATH = \"./../Datastore/Face/\"+NAME+\"/hasFaces\"\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    global MAX_IMAGES \n",
    "    local_MAX_IMAGES=MAX_IMAGES\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(DATABASE_PATH):\n",
    "        local_MAX_IMAGES-=1      \n",
    "        if filename.endswith('.jpg'):\n",
    "            # Construct the file path\n",
    "            filepath = os.path.join(DATABASE_PATH, filename)\n",
    "            # Read the image\n",
    "            img = cv2.imread(filepath)\n",
    "            \n",
    "            ##Filtering for better recognition\n",
    "            greyscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = cascade_classifier.detectMultiScale(greyscale, 1.3, 5)            \n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = img[y:y+ROI_SIZE_XY, x:x+ROI_SIZE_XY]                        \n",
    "            images.append(roi)\n",
    "            labels.append(NAMES.index(NAME))\n",
    "    \n",
    "        if (local_MAX_IMAGES<1):\n",
    "            break\n",
    "    return (images,labels)\n",
    "\n",
    "def train_svm(features, labels):\n",
    "    # Split data into training and testing subsets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Train SVM classifier\n",
    "    svm_classifier = svm.SVC()\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    return svm_classifier, X_test, y_test\n",
    "\n",
    "##implement local binary pattern feature extraction\n",
    "def extract_LBP_features(images):\n",
    "    lbp_features = []\n",
    "\n",
    "    for image in images:\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        radius = 3\n",
    "        n_points = 8 * radius\n",
    "        lbp = local_binary_pattern(gray_image, n_points, radius, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(2**n_points + 1), density=True)\n",
    "        lbp_features.append(hist)\n",
    "\n",
    "    lbp_features = np.array(lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "def main():\n",
    "    ######START PROGRAM\\\\\n",
    "    numerical_labels=[]\n",
    "    for name in NAMES:\n",
    "        try:\n",
    "            index = NAMES.index(name)\n",
    "            numerical_labels.append(index)\n",
    "        except ValueError:\n",
    "            print(\"Element not found\")\n",
    "\n",
    "    ###Gather images and labels in arrays\n",
    "    images = []\n",
    "    labels = []\n",
    "    for name in NAMES:\n",
    "        img, lab = getFiles(name)\n",
    "        images+=(img)\n",
    "        labels+=(lab)\n",
    "        print(len(img),\"Images added for\",name)\n",
    "    print(len(images),\"Images added in total \")\n",
    "\n",
    "\n",
    "\n",
    "    # Step 5: Testing/Evaluation\n",
    "    def test_svm(svm_classifier, X_test, y_test):\n",
    "        \n",
    "        predictions = svm_classifier.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        \n",
    "        \n",
    "    # Extract LBP features\n",
    "    print(\"DONE\\n\\nExtracting LBM features\")\n",
    "    LBP_features = extract_LBP_features(images)\n",
    "\n",
    "    print(\"DONE\\n\\nTraining SVM classifier\")\n",
    "    # Train SVM classifier\n",
    "    svm_classifier, X_test, y_test= train_svm(LBP_features, labels)\n",
    "\n",
    "    print(\"DONE\\n\\nTesting SVM Classifier\")\n",
    "    # Test SVM classifier\n",
    "    print(y_test)\n",
    "    test_svm(svm_classifier, X_test, y_test)\n",
    "\n",
    "\n",
    "    print(\"DONE\\n\\nSaving Classifier\")\n",
    "    # Create the label mapping dictionary\n",
    "    label_mapping = {numerical_labels: label for numerical_labels, label in zip(numerical_labels, NAMES)}\n",
    "    # Save the SVM classifier\n",
    "    with open('svm_classifier.pkl', 'wb') as f:\n",
    "        pickle.dump(svm_classifier, f)\n",
    "\n",
    "    # Save the label encoding mapping\n",
    "    with open('label_mapping.pkl', 'wb') as f:\n",
    "        pickle.dump(label_mapping, f)\n",
    "        \n",
    "    print(\"Saved\\n\\nCOMPLETED\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Binary patteren facial recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE (200, 200, 3)\n",
      "Extracting features\n",
      "LBP FEATREUS IMAGE SHAPE (200, 200, 3)\n",
      "Predicting Label\n",
      "Calculating name\n",
      "Predicted name: Harry\n",
      "SHAPE (200, 200, 3)\n",
      "Extracting features\n",
      "LBP FEATREUS IMAGE SHAPE (200, 200, 3)\n",
      "Predicting Label\n",
      "Calculating name\n",
      "Predicted name: Harry\n",
      "SHAPE (200, 200, 3)\n",
      "Extracting features\n",
      "LBP FEATREUS IMAGE SHAPE (200, 200, 3)\n",
      "Predicting Label\n",
      "Calculating name\n",
      "Predicted name: Harry\n",
      "SHAPE (200, 200, 3)\n",
      "Extracting features\n",
      "LBP FEATREUS IMAGE SHAPE (200, 200, 3)\n",
      "Predicting Label\n",
      "Calculating name\n",
      "Predicted name: Harry\n",
      "SHAPE (200, 200, 3)\n",
      "Extracting features\n",
      "LBP FEATREUS IMAGE SHAPE (200, 200, 3)\n",
      "Predicting Label\n",
      "Calculating name\n",
      "Predicted name: Harry\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "ROI_SIZE_XY=200\n",
    "# Load the SVM classifier\n",
    "with open('svm_classifier.pkl', 'rb') as f:\n",
    "    svm_classifier = pickle.load(f)\n",
    "\n",
    "# Load the label mappingqq\n",
    "with open('label_mapping.pkl', 'rb') as f:\n",
    "    label_mapping = pickle.load(f)\n",
    "    \n",
    "def getName(image):\n",
    "    \n",
    "    print(\"SHAPE\",image.shape)\n",
    "    if image.shape!=(200,200,3):\n",
    "        print(\"BOX IN BAD PLACE\")\n",
    "        return \"TOO CLOSE TO EDGE\"\n",
    "    # Extract LBP features\n",
    "    print(\"Extracting features\")\n",
    "    LBP_features = extract_LBP_features(image)\n",
    "    # Predict the label for the new image\n",
    "    print(\"Predicting Label\")\n",
    "    predicted_label = svm_classifier.predict(LBP_features)[0]\n",
    "    # Map the predicted label to the corresponding name using the label mapping dictionary\n",
    "    print(\"Calculating name\")\n",
    "    predicted_name = label_mapping[predicted_label]\n",
    "\n",
    "    # Print the predicted name\n",
    "    print(\"Predicted name:\", predicted_name)\n",
    "    return predicted_name\n",
    "\n",
    "def extract_LBP_features(image):\n",
    "    lbp_features = []\n",
    "    print(\"LBP FEATREUS IMAGE SHAPE\",image.shape)\n",
    "\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray_image, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(2**n_points + 1), density=True)\n",
    "    lbp_features.append(hist)\n",
    "\n",
    "    lbp_features = np.array(lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "def draw_name(x,y,name,frame):\n",
    "    top_left=(x-10,ROI_SIZE_XY-20)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    font_scale = 3\n",
    "    text_thickness = 2\n",
    "    text = name\n",
    "    text_org = (int(top_left[0]+ROI_SIZE_XY/4),int(top_left[1]+ROI_SIZE_XY/4))  # Place the text just above the rectangle\n",
    "    color=(0,255,0)\n",
    "    if name == \"TOO CLOSE TO EDGE\":\n",
    "        text_thickness=4\n",
    "        color=(0,0,255)\n",
    "        text_org = (100,int(frame_height/2))  # Place the text just above the rectangle\n",
    "        cv2.putText(frame, name, text_org, font, font_scale, color, text_thickness)\n",
    "    else:\n",
    "        cv2.putText(frame, text, text_org, font, font_scale, color, text_thickness)\n",
    "    \n",
    "def main():\n",
    "\n",
    "    ##Load cascade classifier    \n",
    "    cascade_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    camera = cv2.VideoCapture(1,cv2.CAP_DSHOW)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        success, frame = camera.read()\n",
    "        if success:   \n",
    "            cv2.imshow(\"Webcam\", frame) # This will open an independent window\n",
    "                    \n",
    "            greyscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = cascade_classifier.detectMultiScale(greyscale, 1.3, 5)            \n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.imshow(\"Webcam\", frame) # This will open an independent window\n",
    "                \n",
    "            \n",
    "                roi = frame[y:y+ROI_SIZE_XY, x:x+ROI_SIZE_XY]\n",
    "                \n",
    "                name=getName(roi)\n",
    "                draw_name(x,y,name,frame)\n",
    "                cv2.imshow(\"ROI\"+name, roi) # This will open an independent window\n",
    "                cv2.rectangle(frame, (x-1,y-1), (x+w,y+h), (0,255,0), 3)\n",
    "                cv2.imshow(\"Webcam\", frame) # This will open an independent window\n",
    "                    \n",
    "                \n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'): # quit when 'q' is pressed\n",
    "            camera.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
